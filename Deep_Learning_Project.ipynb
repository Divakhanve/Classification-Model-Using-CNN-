{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThxwoHkyzZEc"
      },
      "source": [
        "#  **CLASSIFICATION MODEL**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwJmdhgwdoE",
        "outputId": "a47ab914-46b4-415f-fd59-7ce6e786bd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63sbvcwFcy0b",
        "outputId": "344b6d15-88d7-49fc-cc03-9ee324bceea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvG8rZKh_qn"
      },
      "source": [
        "**These lines import the necessary libraries from TensorFlow, including tools for building neural networks (Keras) and the CIFAR-10 dataset.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfUkS2ULdA6b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET_Dhl2fiJDB"
      },
      "source": [
        "**The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. Each image in the dataset belongs to one of the following 10 classes:**\n",
        "\n",
        "*   Airplane\n",
        "\n",
        "* Automobile\n",
        "\n",
        "* Bird\n",
        "\n",
        "* Cat\n",
        "\n",
        "* Deer\n",
        "\n",
        "* Dog\n",
        "\n",
        "* Frog\n",
        "\n",
        "* Horse\n",
        "\n",
        "* Truck\n",
        "\n",
        "* ship\n",
        "\n",
        "**So, the dataset includes images of various objects and animals, and each image is labeled with the corresponding class. The goal of a machine learning model trained on this dataset is to learn how to classify new images into one of these 10 classes based on the patterns and features it learns from the training data.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYn1-MmAjDab"
      },
      "source": [
        "**Normalizing the pixel values refers to adjusting the range of pixel values in the images to make them more suitable for training a machine learning model, particularly a neural network.**\n",
        "\n",
        "**The original pixel values in images are typically in the range of 0 to 255, where 0 represents the absence of color (black) and 255 represents the maximum intensity of color (white). Normalizing these pixel values to a new range of 0 to 1 involves dividing each pixel value by 255. This transformation ensures that all pixel values are now within the range [0, 1].**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xps8uKaJdP27",
        "outputId": "2f9e4e34-2b8b-4cc0-f935-cfa556c7702f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiTk57B-jrhg"
      },
      "source": [
        "**This line creates an empty neural network model. The model will be filled with layers to form a structure that can learn patterns from the images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RS4bkZ6dQdt"
      },
      "outputs": [],
      "source": [
        "# Create a simple CNN model\n",
        "model = models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "638p7ejQnEbS"
      },
      "source": [
        "**These lines add the first convolutional layer to the model. Convolutional layers help the model learn features from the images.**\n",
        "\n",
        "**Convolutional Layer:**\n",
        "\n",
        "Think of the convolutional layer as a feature detector. It scans the input image looking for specific patterns, textures, or features. It does this by applying small filters (also called kernels) to small patches of the image.\n",
        "Imagine you are looking at a picture through a small window, and you move the window across the entire image, observing patterns like edges, colors, or textures.\n",
        "\n",
        "**Activation Function 'ReLU' (Rectified Linear Unit):**\n",
        "\n",
        "The activation function introduces non-linearity to the model. In simple terms, it helps the neural network learn complex patterns and relationships in the data.\n",
        "The ReLU activation function turns all negative values to zero and leaves positive values unchanged. It is a simple way to add non-linearity, allowing the model to learn more intricate features and patterns.\n",
        "\n",
        "**input shape**\n",
        "\n",
        "**Height:** The number of pixels in the vertical direction of an image.\n",
        "\n",
        "**Width:** The number of pixels in the horizontal direction of an image.\n",
        "\n",
        "**Channels:** The number of color channels in an image.\n",
        "\n",
        "\n",
        "**Max Pooling:**\n",
        "\n",
        "Max pooling is like zooming out from the image and keeping only the most important information. It reduces the spatial dimensions of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtwOYwSidl7o"
      },
      "outputs": [],
      "source": [
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNc0bOQoUVH"
      },
      "source": [
        "**These lines add a second set of convolutional and max pooling layers, further extracting features from the images.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVV7T73deXAl"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzDzH_XXpc92"
      },
      "source": [
        "**Flatten Layer:** Flattens the 3D data into a 1D array.\n",
        "\n",
        "**Dense Layers:** Process the flattened data, learning patterns and relationships.\n",
        "\n",
        "**Softmax Activation:** Provides probabilities for each class, helping the model make a final decision on the most likely class for the input image.\n",
        "\n",
        "Together, these layers form the final part of the neural network responsible for making predictions based on the features learned from the input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTrfucQJfujB"
      },
      "outputs": [],
      "source": [
        "# Flatten layer and fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6YY22Qqa7p"
      },
      "source": [
        "**Now this code configure the model for training. The 'adam' optimizer adjusts the model to reduce errors. 'Sparse_categorical_crossentropy' is a measure of the difference between the predicted and actual classes. 'Accuracy' is a metric that measures how well the model is performing.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Qs5eppfycf"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLtMMmAJf069",
        "outputId": "6cc942a2-4ea0-4a55-b990-fb10abf0df0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 15, 15, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315722 (1.20 MB)\n",
            "Trainable params: 315722 (1.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7AL8NYWt3Qy"
      },
      "source": [
        "**This line trains the model using the training images and labels. The model learns to make better predictions by adjusting its internal parameters over 10 training epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb73XtR6f4CK",
        "outputId": "ddea96e7-343f-4943-b6d4-4cf50655012d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 77s 48ms/step - loss: 1.4249 - accuracy: 0.4916\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 75s 48ms/step - loss: 1.0664 - accuracy: 0.6299\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 71s 46ms/step - loss: 0.9281 - accuracy: 0.6768\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.8251 - accuracy: 0.7126\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 68s 43ms/step - loss: 0.7463 - accuracy: 0.7394\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6669 - accuracy: 0.7663\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6055 - accuracy: 0.7877\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 0.5406 - accuracy: 0.8109\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4873 - accuracy: 0.8292\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4362 - accuracy: 0.8460\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb46121d630>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rnUHS0DvKRh"
      },
      "source": [
        "**These lines evaluate the model's performance on the test dataset, calculating the loss (how far off the predictions are) and accuracy.**\n",
        "\n",
        " **The final evaluation results, showing how well the model performed on the test data. The lower the loss and the higher the accuracy, the better the model is at making predictions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Z-3Yzof7Jo",
        "outputId": "b271a830-32b7-4d1b-e207-13cb9b360077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 17ms/step - loss: 1.0247 - accuracy: 0.6950\n",
            "Test Loss: 1.0247\n",
            "Test Accuracy: 69.50%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eWh5JdxnzMV",
        "outputId": "e74d325c-c3a4-4763-d3e3-a9f997500de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Classification model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp5O8jXWy6p5"
      },
      "source": [
        "**LET'S TEST THE CLASSIFICATION MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsXU51nwwb33",
        "outputId": "05a492ef-b7e6-4ecb-88c8-759a48fb5bfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eb4619b2f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n",
            "Predicted Class: 9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Classification model.h5')\n",
        "\n",
        "img_path = '/content/Truck.jpeg'\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "predicted_class = np.argmax(predictions)\n",
        "print(f\"Predicted Class: {predicted_class}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olO-Gsc4yo46"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}